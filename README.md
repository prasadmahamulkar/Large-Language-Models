<h1 align="center"> Large Language Models Notebooks</h1>
<p align="center">
  ü§ó<a href="https://www.google.com">Hugging Face</a> ‚Ä¢ üíª<a href="https://www.google.com">Blogs</a>
</p>

 ![llm tree-min](https://github.com/prasadmahamulkar/Large-Language-Models-llm-/assets/93597510/9da2115a-3eed-4f5f-ac72-125800a0eb6e)
 
https://colab.research.google.com/drive/1zki5smRQDDIYGZ9LuTzVLV_qcq4dH8Aj
<h2>üìùNotebooks</h2>
<p>The table lists various models and their corresponding links, allowing easy access and understanding of step-by-step model fine-tuning. </p>


  | Fine-tune Models                      | Dataset | Notebooks | 
|----------------------------|-----------------------------------------------|-----------------------|
| Phi -2 - [link](https://huggingface.co/prsdm/phi-2-medquad)                      | [Dataset](https://huggingface.co/datasets/prsdm/MedQuad-phi2-1k)                 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]([https://colab.research.google.com/drive/1Xx5pu64j_uuLbnE3C0imgUc_zWkfXfSZ?usp=sharing](https://colab.research.google.com/drive/1zki5smRQDDIYGZ9LuTzVLV_qcq4dH8Aj)               |       
| Llama-2 7b   |                       W.I.P                        | W.I.P               |
| Logistic Regression        |                                               | 0.621                | 
